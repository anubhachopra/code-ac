{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebef52ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-11T14:36:25.109459Z",
     "iopub.status.busy": "2023-12-11T14:36:25.107573Z",
     "iopub.status.idle": "2023-12-11T14:36:28.085052Z",
     "shell.execute_reply": "2023-12-11T14:36:28.086466Z"
    },
    "papermill": {
     "duration": 2.998185,
     "end_time": "2023-12-11T14:36:28.088311",
     "exception": false,
     "start_time": "2023-12-11T14:36:25.090126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'section' column does not contain missing values.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "directory = ''\n",
    "\n",
    "# Load your Excel file using openpyxl\n",
    "df1 = pd.read_excel(f'{directory}/Output/Formating Urban/Section_codes_current.xlsx', header=0, engine='openpyxl')\n",
    "\n",
    "# Loading legal data\n",
    "df2 = pd.read_csv(f'{directory}/Data/master_table1.csv')\n",
    "\n",
    "# Creating subset of data (enter lowercase)\n",
    "desired_state1 = \"Washington\"\n",
    "desired_state2 = \"washington\"\n",
    "subset_df1 = df1[df1['STATE'] == desired_state1]\n",
    "subset_df2 = df2[df2['State'] == desired_state2]\n",
    "\n",
    "# Check for NA\n",
    "if subset_df2['section'].isna().any():\n",
    "    print(\"The 'section' column contains missing values.\")\n",
    "else:\n",
    "    print(\"The 'section' column does not contain missing values.\")\n",
    "\n",
    "# Clean section column\n",
    "subset_df2['section'] = subset_df2['section'].str.replace('section-', '', case=False)\n",
    "subset_df2['section'] = subset_df2['section'].str.replace('-', '.')  # Replace first hyphen with colon\n",
    "# subset_df2['section'] = subset_df2['section'].str.upper()\n",
    "# subset_df2['section'] = subset_df2['section'].apply(lambda x: x[:x.rfind('-')] + '.' + x[x.rfind('-')+1:])\n",
    "\n",
    "# subset_df2.head(5)\n",
    "\n",
    "# Merge the subsetted dataframes on 'Section Code' and 'Section'\n",
    "merged_df = pd.merge(subset_df1, subset_df2[['State','section', 'text']], left_on='Section Code', right_on='section', how='left')\n",
    "\n",
    "# merged_df.head()\n",
    "\n",
    "# Save the merged data to an Excel file\n",
    "merged_df.to_excel(f'{directory}/Output/Matching Urban to Drexel/Section_codes_merged_{desired_state2}.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df2a06",
   "metadata": {
    "papermill": {
     "duration": 0.016928,
     "end_time": "2023-12-11T14:36:28.123709",
     "exception": false,
     "start_time": "2023-12-11T14:36:28.106781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.534495,
   "end_time": "2023-12-11T14:36:28.570066",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/Anubha/Downloads/Regulatory Project/Merging-WASHINGTON.ipynb",
   "output_path": "/Users/Anubha/Downloads/Regulatory Project/Merging-WASHINGTON.ipynb",
   "parameters": {},
   "start_time": "2023-12-11T14:36:24.035571",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
